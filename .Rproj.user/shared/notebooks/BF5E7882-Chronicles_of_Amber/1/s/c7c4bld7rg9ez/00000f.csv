"0","# N-Gram analysis"
"0","# bigram most frequent words that appear next to each other - token = ""ngrams"", n = 2"
"0","# create bigrams of the chronicles of amber"
"0","amber_grams <- amber_books %>%"
"0","  filter(chapter > 0) %>%"
"0","  unnest_tokens(bigram, text, token = ""ngrams"", n=2)"
"0",""
"0","# view the most used bigrams"
"0","# amber_grams %>%"
"0","#   count(bigram, sort = TRUE)"
"0","snowball_sw <- get_stopwords(""en"", ""snowball"")"
"0",""
"0",""
"0","# adding tir na nog'th to stop words"
"0","word = c(""tir"", ""na"", ""nog'th"", ""said"")"
"0",""
"0","lexicon = c( ""custom"",  ""custom"", ""custom"", ""custom"")"
"0",""
"0","data <- data.frame(word, lexicon)"
"0","custom_stop_words <- rbind(data, snowball_sw)"
"0",""
"0","# split the bigrams into two separate columns word1 and word2"
"0","bigrams_separated <- amber_grams %>%"
"0","  separate(bigram, c(""word1"", ""word2""), sep = "" "")"
"0",""
"0","# remove stopwords from bigrams"
"0","bigrams_filtered <- bigrams_separated %>%"
"0","  filter(!word1 %in% custom_stop_words$word) %>%"
"0","  filter(!word2 %in% custom_stop_words$word) %>%"
"0","  # filter(!word3 %in% stop_words$word) %>%"
"0","  filter(!is.na(word1)) %>%"
"0","  filter(!is.na(word2)) "
"0","  # filter(!is.na(word3))"
"0",""
"0","# new bigram counts without stopwords"
"0","bigram_counts <- bigrams_filtered %>%"
"0","  filter(chapter > 0) %>%"
"0","  count(word1, word2, sort = TRUE)"
"0",""
"0","head(bigram_counts)"
