---
title: "Chronicles_of_Amber"
author: "Crystal Sawtelle"
date: "2023-03-03"
output:
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(Amber)
install.packages("tidyverse", repos = "http://cran.us.r-project.org")
library(tidyverse)
library(dplyr)
library(stringr)
install.packages("tidytext", repos = "http://cran.us.r-project.org")
library(tidytext)
install.packages("textclean", repos = "http://cran.us.r-project.org")
library(textclean)
install.packages("tm", repos = "http://cran.us.r-project.org")
library(tm)
library(tidyr)
```


```{r}
amber_books <- chronicles_of_amber() %>%
  group_by(book) %>%
  mutate(linenumber = row_number(),
         chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]")))) %>%
  ungroup()

#amber_books
```




```{r}
# using tidytext to unnest each word in the book

amber_tidy <- amber_books %>%
  unnest_tokens(word, text)
#amber_tidy
```

```{r}
# remove stop words "the", "a", "if", etc.

data("stop_words")

amber_tidy <- amber_tidy %>%
  anti_join(stop_words, by = "word")

amber_tidy %>%
  count(word, sort = TRUE)

```



Will need to add a few word contractions like "i'd", "i'm", and "it's" to the stop_words 


```{r}
# graph the top most used words

amber_tidy %>%
  count(word, sort = TRUE) %>%
  filter(n > 600) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n)) +
  geom_col() +
  coord_flip()

# amber_tidy_graph
# 
# ggplot(amber_tidy, aes(word, n)) +
#   geom_col() +
#   coord_flip()
```

```{r}
# create a custom stop words list to add to standard stop words
word = c("i’d", "i’m", "it’s", "don’t", "we’ve", "have’t", "didn’t", "you’re", "you’ve", "i’ve", "hadn’t", "we’ve", "i’ll", "he’s", "can’t", "wasn’t", "what’s", "won’t", "we’d", "doesn’t", "you’d", "he’d", "wouldn’t", "let’s", "there’s", "she’s", "she’d", "you’ll", "they’re", "we’ll", "weren’t", "aren’t")

lexicon = c( "custom",  "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom")

data <- data.frame(word, lexicon)
custom_stop_words <- rbind(data, stop_words)
custom_stop_words

# rerunning amber tidy with new custom_stop_words
amber_tidy <- anti_join(amber_tidy, custom_stop_words, by = "word")

amber_tidy %>%
  count(word, sort = TRUE)

amber_tidy %>%
  count(word, sort = TRUE) %>%
  filter(n > 600) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n)) +
  geom_col() +
  coord_flip()
```


```{r, warning=FALSE}
# graph the sentiment of every 40 pages
amber_sentiment <- amber_tidy %>%
  inner_join(get_sentiments("bing")) %>%
  count(book, index = linenumber %/% 40, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative)

ggplot(amber_sentiment, aes(index, sentiment, fill = book)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~book, ncol = 2, scales = "free_x")
```


```{r}
# break out the first book in the series
nine_princes_in_amber <- chronicles_of_amber() %>%
  group_by(book) %>%
  filter(book == "Nine Princes in Amber") %>%
  mutate(linenumber = row_number(),
         chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]"))))

# nine_princes_in_amber
```

