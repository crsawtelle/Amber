install.packages("textdata", repos = "http://cran.us.r-project.org")
install.packages("tidytext", repos = "http://cran.us.r-project.org")
install.packages("tidyverse", repos = "http://cran.us.r-project.org")
library(textdata)
install.packages("textclean", repos = "http://cran.us.r-project.org")
install.packages("tidyverse", repos = "http://cran.us.r-project.org")
library(textclean)
install.packages("tm", repos = "http://cran.us.r-project.org")
library(tm)
# used for word cloud
install.packages("wordcloud", repos = "http://cran.us.r-project.org")
library(wordcloud)
# reshape2 is used to make a comparison cloud
install.packages("reshape2", repos = "http://cran.us.r-project.org")
library(reshape2)
# used to manipulate and analyze networds - create columns of "from" and "to" to visualize a network
install.packages("igraph", repos = "http://cran.us.r-project.org")
library(igraph)
# used to graph network created from igraph package
install.packages("ggraph", repos = "http://cran.us.r-project.org")
library(ggraph)
# used for counting and correlating pairs of words within sections of text
install.packages("widyr", repos = "http://cran.us.r-project.org")
library(widyr)
library(tidyr)
library(ggplot2)
remove.packages(rlang)
remove.packages("rlang")
install.packages("rlang")
install.packages("rlang")
knitr::opts_chunk$set(echo = TRUE)
library(Amber)
install.packages("tidyverse", repos = "http://cran.us.r-project.org")
library(tidyverse)
library(dplyr)
library(stringr)
install.packages("tidytext", repos = "http://cran.us.r-project.org")
library(tidytext)
# need for afinn lexicon
install.packages("textdata", repos = "http://cran.us.r-project.org")
library(textdata)
install.packages("textclean", repos = "http://cran.us.r-project.org")
library(textclean)
install.packages("tm", repos = "http://cran.us.r-project.org")
library(tm)
# used for word cloud
install.packages("wordcloud", repos = "http://cran.us.r-project.org")
library(wordcloud)
# reshape2 is used to make a comparison cloud
install.packages("reshape2", repos = "http://cran.us.r-project.org")
library(reshape2)
# used to manipulate and analyze networds - create columns of "from" and "to" to visualize a network
install.packages("igraph", repos = "http://cran.us.r-project.org")
library(igraph)
# used to graph network created from igraph package
install.packages("ggraph", repos = "http://cran.us.r-project.org")
library(ggraph)
# used for counting and correlating pairs of words within sections of text
install.packages("widyr", repos = "http://cran.us.r-project.org")
library(widyr)
library(tidyr)
library(ggplot2)
library(rlang)
amber_books <- chronicles_of_amber() %>%
group_by(book) %>%
mutate(linenumber = row_number(),
chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]")))) %>%
ungroup()
# amber_books
# using tidytext to unnest each word in the book
amber_tidy <- amber_books %>%
unnest_tokens(word, text)
#amber_tidy
# remove stop words "the", "a", "if", etc.
data("stop_words")
amber_tidy <- amber_tidy %>%
anti_join(stop_words, by = "word")
amber_tidy %>%
count(word, sort = TRUE)
# # create a custom stop words list to add to standard stop words
# word = c("i’d", "i’m", "it’s", "don’t", "we’ve", "have’t", "didn’t", "you’re", "you’ve", "i’ve", "hadn’t", "we’ve", "i’ll", "he’s", "can’t", "wasn’t", "what’s", "won’t", "we’d", "doesn’t", "you’d", "he’d", "wouldn’t", "let’s", "there’s", "she’s", "she’d", "you’ll", "they’re", "we’ll", "weren’t", "aren’t")
#
# lexicon = c( "custom",  "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom")
#
# data <- data.frame(word, lexicon)
# custom_stop_words <- rbind(data, stop_words)
# # custom_stop_words
#
# # rerunning amber tidy with new custom_stop_words
# amber_tidy <- anti_join(amber_tidy, custom_stop_words, by = "word")
#
# amber_tidy %>%
#   count(word, sort = TRUE)
amber_tidy_graph <- amber_tidy %>%
count(word, sort = TRUE) %>%
filter(n > 600) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col(fill = "navy") +
coord_flip()
amber_tidy_graph %>% plotly::ggplotly()
amber_tidy_graph
knitr::opts_chunk$set(echo = TRUE)
library(Amber)
if (!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
library(tidyverse)
library(dplyr)
install.packages("knitr", repos = "http://cran.us.r-project.org")
library(knitr)
install.packages("tidytext", repos = "http://cran.us.r-project.org")
install.packages("knitr", repos = "http://cran.us.r-project.org")
library(tidytext)
install.packages("rlang", repos = "http://cran.us.r-project.org", version = "1.1.0")
library(rlang)
amber_books <- chronicles_of_amber() %>%
group_by(book) %>%
mutate(linenumber = row_number(),
chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]")))) %>%
ungroup()
nine_princes_in_amber <- amber_books %>%
group_by(book) %>%
filter(book == "Nine Princes in Amber")
# nine_princes_in_amber
the_guns_of_avalon <- amber_books %>%
group_by(book) %>%
filter(book == "The Guns of Avalon")
# the_guns_of_avalon
sign_of_the_unicorn <- amber_books %>%
group_by(book) %>%
filter(book == "Sign of the Unicorn")
# sign_of_the_unicorn
the_hand_of_oberon <- amber_books %>%
group_by(book) %>%
filter(book == "The Hand of Oberon")
# the_hand_of_oberon
the_courts_of_chaos <- amber_books %>%
group_by(book) %>%
filter(book == "The Courts of Chaos")
# the_courts_of_chaos
the_trumps_of_doom <- amber_books %>%
group_by(book) %>%
filter(book == "The Trumps of Doom")
# the_trumps_of_doom
blood_of_amber <- amber_books %>%
group_by(book) %>%
filter(book == "Blood of Amber")
# blood_of_amber
sign_of_chaos <- amber_books %>%
group_by(book) %>%
filter(book == "Sign of Chaos")
# sign_of_chaos
knight_of_shadows <- amber_books %>%
group_by(book) %>%
filter(book == "Knight of Shadows")
# knight_of_shadows
prince_of_chaos <- amber_books %>%
group_by(book) %>%
filter(book == "Prince of Chaos")
amber_books_table <- rbind(head(nine_princes_in_amber, 1), head(the_guns_of_avalon, 1), head(sign_of_the_unicorn, 1),
head(the_hand_of_oberon, 1), head(the_courts_of_chaos, 1), head(the_trumps_of_doom, 1),
head(blood_of_amber, 1), head(sign_of_chaos, 1), head(knight_of_shadows, 1), head(prince_of_chaos, 1) )
knitr::kable(amber_books_table)
amber_tidy <- amber_books %>%
unnest_tokens(word, text)
data("stop_words")
amber_tidy <- amber_tidy %>%
anti_join(stop_words, by = "word")
amber_graph <- amber_tidy %>%
count(word, sort = TRUE) %>%
filter(n > 600) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col() +
coord_flip()
amber_graph
install.packages("rlang", repos = "http://cran.us.r-project.org", version = "1.1.0")
amber_tidy <- amber_books %>%
unnest_tokens(word, text)
data("stop_words")
amber_tidy <- amber_tidy %>%
anti_join(stop_words, by = "word")
amber_graph <- amber_tidy %>%
count(word, sort = TRUE) %>%
filter(n > 600) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col() +
coord_flip() +
labs(title = "Top 10 used word in The Chronicles of Amber")
amber_graph
knitr::opts_chunk$set(echo = TRUE)
library(Amber)
install.packages("tidyverse", repos = "http://cran.us.r-project.org")
library(tidyverse)
library(dplyr)
library(stringr)
install.packages("tidytext", repos = "http://cran.us.r-project.org")
library(tidytext)
# need for afinn lexicon
install.packages("textdata", repos = "http://cran.us.r-project.org")
install.packages("tidytext", repos = "http://cran.us.r-project.org")
install.packages("tidyverse", repos = "http://cran.us.r-project.org")
library(textdata)
install.packages("textclean", repos = "http://cran.us.r-project.org")
install.packages("tidyverse", repos = "http://cran.us.r-project.org")
library(textclean)
install.packages("tm", repos = "http://cran.us.r-project.org")
library(tm)
# used for word cloud
install.packages("wordcloud", repos = "http://cran.us.r-project.org")
library(wordcloud)
# reshape2 is used to make a comparison cloud
install.packages("reshape2", repos = "http://cran.us.r-project.org")
library(reshape2)
# used to manipulate and analyze networds - create columns of "from" and "to" to visualize a network
install.packages("igraph", repos = "http://cran.us.r-project.org")
library(igraph)
# used to graph network created from igraph package
install.packages("ggraph", repos = "http://cran.us.r-project.org")
library(ggraph)
# used for counting and correlating pairs of words within sections of text
install.packages("widyr", repos = "http://cran.us.r-project.org")
library(widyr)
library(tidyr)
library(ggplot2)
amber_books <- chronicles_of_amber() %>%
group_by(book) %>%
mutate(linenumber = row_number(),
chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]")))) %>%
ungroup()
# amber_books
# using tidytext to unnest each word in the book
amber_tidy <- amber_books %>%
unnest_tokens(word, text)
#amber_tidy
# remove stop words "the", "a", "if", etc.
data("stop_words")
amber_tidy <- amber_tidy %>%
anti_join(stop_words, by = "word")
amber_tidy %>%
count(word, sort = TRUE)
# # create a custom stop words list to add to standard stop words
# word = c("i’d", "i’m", "it’s", "don’t", "we’ve", "have’t", "didn’t", "you’re", "you’ve", "i’ve", "hadn’t", "we’ve", "i’ll", "he’s", "can’t", "wasn’t", "what’s", "won’t", "we’d", "doesn’t", "you’d", "he’d", "wouldn’t", "let’s", "there’s", "she’s", "she’d", "you’ll", "they’re", "we’ll", "weren’t", "aren’t")
#
# lexicon = c( "custom",  "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom", "custom")
#
# data <- data.frame(word, lexicon)
# custom_stop_words <- rbind(data, stop_words)
# # custom_stop_words
#
# # rerunning amber tidy with new custom_stop_words
# amber_tidy <- anti_join(amber_tidy, custom_stop_words, by = "word")
#
# amber_tidy %>%
#   count(word, sort = TRUE)
amber_tidy_graph <- amber_tidy %>%
count(word, sort = TRUE) %>%
filter(n > 600) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col(fill = "navy") +
coord_flip()
amber_tidy_graph %>% plotly::ggplotly()
nine_princes_word <- amber_tidy %>%
group_by(book) %>%
filter(book == "Nine Princes in Amber") %>%
count(word, sort = TRUE) %>%
mutate(word = reorder(word, n)) %>%
slice(1:5)
nine_princes_graph <- ggplot(nine_princes_word, aes(word, n)) +
geom_col(fill = c("lightsteelblue4", "lightsteelblue3", "lightsteelblue2", "lightsteelblue1", "lightsteelblue")) +
coord_flip(ylim = c(0, 220)) +
labs(title = "Nine Princes of Amber") +
theme(plot.title = element_text(size = 14), axis.text = element_text(size = 14))
# nine_princes_graph %>% plotly::ggplotly()
guns_avalon_word <- amber_tidy %>%
group_by(book) %>%
filter(book == "The Guns of Avalon") %>%
count(word, sort = TRUE) %>%
mutate(word = reorder(word, n)) %>%
slice(1:5)
guns_avalon_graph <- ggplot(guns_avalon_word, aes(word, n)) +
geom_col(fill = c("lightsteelblue4", "lightsteelblue3", "lightsteelblue2", "lightsteelblue1", "lightsteelblue")) +
coord_flip(ylim = c(0, 220)) +
labs(title = "The Guns of Avalon") +
theme(plot.title = element_text(size = 14), axis.text = element_text(size = 14))
# guns_avalon_graph %>% plotly::ggplotly()
sign_unicorn_word <- amber_tidy %>%
group_by(book) %>%
filter(book == "Sign of the Unicorn") %>%
count(word, sort = TRUE) %>%
mutate(word = reorder(word, n)) %>%
slice(1:5)
sign_unicorn_graph <- ggplot(sign_unicorn_word, aes(word, n)) +
geom_col(fill = c("lightsteelblue4", "lightsteelblue3", "lightsteelblue2", "lightsteelblue1", "lightsteelblue")) +
coord_flip(ylim = c(0, 220)) +
labs(title = "Sign of the Unicorn") +
theme(plot.title = element_text(size = 14), axis.text = element_text(size = 14))
# sign_unicorn_graph %>% plotly::ggplotly()
hand_oberon_word <- amber_tidy %>%
group_by(book) %>%
filter(book == "The Hand of Oberon") %>%
count(word, sort = TRUE) %>%
mutate(word = reorder(word, n)) %>%
slice(1:5)
hand_oberon_graph <- ggplot(hand_oberon_word, aes(word, n)) +
geom_col(fill = c("lightsteelblue4", "lightsteelblue3", "lightsteelblue2", "lightsteelblue1", "lightsteelblue")) +
coord_flip(ylim = c(0, 220)) +
labs(title = "The Hand of Oberon") +
theme(plot.title = element_text(size = 14), axis.text = element_text(size = 14))
# hand_oberon_graph %>% plotly::ggplotly()
courts_chaos_word <- amber_tidy %>%
group_by(book) %>%
filter(book == "The Courts of Chaos") %>%
count(word, sort = TRUE) %>%
mutate(word = reorder(word, n)) %>%
slice(1:5)
courts_chaos_graph <- ggplot(courts_chaos_word, aes(word, n)) +
geom_col(fill = c("lightsteelblue4", "lightsteelblue3", "lightsteelblue2", "lightsteelblue1", "lightsteelblue")) +
coord_flip(ylim = c(0, 220)) +
labs(title = "The Courts of Chaos") +
theme(plot.title = element_text(size = 14), axis.text = element_text(size = 14))
# courts_chaos_graph %>% plotly::ggplotly()
trumps_doom_word <- amber_tidy %>%
group_by(book) %>%
filter(book == "The Trumps of Doom") %>%
count(word, sort = TRUE) %>%
mutate(word = reorder(word, n)) %>%
slice(1:5)
trumps_doom_graph <- ggplot(trumps_doom_word, aes(word, n)) +
geom_col(fill = c("lightsteelblue4", "lightsteelblue3", "lightsteelblue2", "lightsteelblue1", "lightsteelblue")) +
coord_flip(ylim = c(0, 220)) +
labs(title = "The Trumps of Doom") +
theme(plot.title = element_text(size = 14), axis.text = element_text(size = 14))
# trumps_doom_graph %>% plotly::ggplotly()
blood_amber_word <- amber_tidy %>%
group_by(book) %>%
filter(book == "Blood of Amber") %>%
count(word, sort = TRUE) %>%
mutate(word = reorder(word, n)) %>%
slice(1:5)
blood_amber_graph <- ggplot(blood_amber_word, aes(word, n)) +
geom_col(fill = c("lightsteelblue4", "lightsteelblue3", "lightsteelblue2", "lightsteelblue1", "lightsteelblue")) +
coord_flip(ylim = c(0, 220)) +
labs(title = "Blood of Amber") +
theme(plot.title = element_text(size = 14), axis.text = element_text(size = 14))
# blood_amber_graph %>% plotly::ggplotly()
sign_chaos_word <- amber_tidy %>%
group_by(book) %>%
filter(book == "Sign of Chaos") %>%
count(word, sort = TRUE) %>%
mutate(word = reorder(word, n)) %>%
slice(1:5)
sign_chaos_graph <- ggplot(sign_chaos_word, aes(word, n)) +
geom_col(fill = c("lightsteelblue4", "lightsteelblue3", "lightsteelblue2", "lightsteelblue1", "lightsteelblue")) +
coord_flip(ylim = c(0, 220)) +
labs(title = "Sign of Chaos") +
theme(plot.title = element_text(size = 14), axis.text = element_text(size = 14))
# sign_chaos_graph %>% plotly::ggplotly()
knight_shadow_word <- amber_tidy %>%
group_by(book) %>%
filter(book == "Knight of Shadows") %>%
count(word, sort = TRUE) %>%
mutate(word = reorder(word, n)) %>%
slice(1:5)
knight_shadow_graph <- ggplot(knight_shadow_word, aes(word, n)) +
geom_col(fill = c("lightsteelblue4", "lightsteelblue3", "lightsteelblue2", "lightsteelblue1", "lightsteelblue")) +
coord_flip(ylim = c(0, 220)) +
labs(title = "Knight of Shadows") +
theme(plot.title = element_text(size = 14), axis.text = element_text(size = 14))
# knight_shadow_graph %>% plotly::ggplotly()
prince_chaos_word <- amber_tidy %>%
group_by(book) %>%
filter(book == "Prince of Chaos") %>%
count(word, sort = TRUE) %>%
mutate(word = reorder(word, n)) %>%
slice(1:5)
prince_chaos_graph <- ggplot(prince_chaos_word, aes(word, n), fill = word) +
geom_col(fill = c("lightsteelblue4", "lightsteelblue3", "lightsteelblue2", "lightsteelblue1", "lightsteelblue")) +
coord_flip(ylim = c(0, 220)) +
labs(title = "Prince of Chaos") +
theme(plot.title = element_text(size = 14), axis.text = element_text(size = 14))
# prince_chaos_graph %>% plotly::ggplotly()
cowplot::plot_grid(nine_princes_graph, guns_avalon_graph, sign_unicorn_graph, hand_oberon_graph, courts_chaos_graph,
trumps_doom_graph, blood_amber_graph, sign_chaos_graph, knight_shadow_graph, prince_chaos_graph, ncol = 2)
# graph the sentiment of every 40 pages
amber_sentiment <- amber_tidy %>%
inner_join(get_sentiments("bing"), by = join_by(word)) %>%
count(book, index = linenumber %/% 40, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
ggplot(amber_sentiment, aes(index, sentiment, fill = book)) +
geom_col(show.legend = FALSE) +
facet_wrap(~book, ncol = 2, scales = "free_x")
amber_tidy %>%
count(word) %>%
with(wordcloud(word, n, max.words = 100))
amber_bing_word_counts <- amber_tidy %>%
inner_join(get_sentiments("bing"), by = join_by(word)) %>%
count(word, sentiment, sort = TRUE) %>%
ungroup()
amber_bing_word_counts %>%
group_by(sentiment) %>%
top_n(10) %>%
ungroup() %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n, fill = sentiment)) +
geom_col() +
facet_wrap(~sentiment, scales = "free_y") +
coord_flip()
amber_tidy %>%
inner_join(get_sentiments("bing"), by = join_by(word)) %>%
count(word, sentiment, sort = TRUE) %>%
acast(word ~ sentiment, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("steelblue4", "magenta4"), max.words = 100)
amber_sentences <- chronicles_of_amber() %>%
unnest_tokens(sentence, text, token = "sentences")
amber_sentences$sentence[20]
amber_chapters <- chronicles_of_amber() %>%
group_by(book) %>%
unnest_tokens(chapter, text, token = "regex", pattern = "Chapter|chapter [\\divxlc]") %>%
ungroup()
amber_chapters %>%
group_by(book) %>%
summarise(chapters = n())
amber_negative <- get_sentiments("bing") %>%
filter(sentiment == "negative")
amber_word_count <- amber_tidy %>%
group_by(book, chapter) %>%
summarise(words = n())
amber_tidy %>%
semi_join(amber_negative) %>%
group_by(book, chapter) %>%
summarize(negativewords = n()) %>%
left_join(amber_word_count, by = c("book", "chapter")) %>%
mutate(ratio = negativewords/words) %>%
filter(chapter != 0) %>%
top_n(1) %>%
ungroup()
amber_positive <- get_sentiments("bing") %>%
filter(sentiment == "positive")
amber_tidy %>%
semi_join(amber_positive) %>%
group_by(book, chapter) %>%
summarize(positive_words = n()) %>%
left_join(amber_word_count, by = c("book", "chapter")) %>%
mutate(ratio = positive_words/words) %>%
filter(chapter != 0) %>%
top_n(1) %>%
ungroup()
book_words <- chronicles_of_amber() %>%
unnest_tokens(word, text) %>%
count(book, word, sort = TRUE) %>%
ungroup()
total_words <- book_words %>%
group_by(book) %>%
summarize(total = sum(n))
book_words <- left_join(book_words, total_words)
book_words
tf_dist_amber <- ggplot(book_words, aes(n/total, fill = book)) +
geom_histogram(show.legend = FALSE) +
xlim(NA, 0.0009) +
facet_wrap(~book, ncol = 2, scales = "free_y")
tf_dist_amber
freq_by_rank <- book_words %>%
group_by(book) %>%
mutate(rank = row_number(), term_freq = n/total)
head(freq_by_rank)
tail(freq_by_rank)
freq_by_rank %>%
ggplot(aes(rank, term_freq, color = book)) +
geom_line(size = 1.1, alpha = 0.8, show.legend = FALSE) +
scale_x_log10() +
scale_y_log10()
rank_subset <- freq_by_rank %>%
filter(rank < 500, rank > 10)
lm(log10(term_freq) ~ log10(rank), data = rank_subset)
freq_by_rank %>%
ggplot(aes(rank, term_freq, color = book)) +
geom_abline(intercept = -0.77, slope = -1.04, color = "navy", linetype = 2) +
geom_line(size = 1.1, alpha = 0.8, show.legend = FALSE) +
scale_x_log10() +
scale_y_log10()
book_words <- book_words %>%
bind_tf_idf(word, book, n)
book_words
# look at terms with higher tf-idf - typically proper nouns (i.e. names)
book_words %>%
select(-total) %>%
arrange(desc(tf_idf))
book_words %>%
arrange(desc(tf_idf)) %>%
mutate(word = factor(word, levels = rev(unique(word)))) %>%
group_by(book) %>%
top_n(5) %>%
ungroup() %>%
ggplot(aes(x = fct_reorder(word, tf_idf), tf_idf, fill = book)) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "tf-idf") +
facet_wrap(~book, ncol = 2, scales = "free") +
coord_flip()
amber_tidy_graph %>% plotly::ggplotly()
View(chronicles_of_amber())
?chronicles_of_amber
?nine_princes_in_amber
?chronicles_of_amber
amber_books <- chronicles_of_amber() %>%
group_by(book) %>%
mutate(linenumber = row_number(),
chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]")))) %>%
ungroup()
amber_books
